{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================training classifier==================\n",
      "model : SVM\n",
      "\n",
      "\n",
      "model : Naive bayse\n",
      "\n",
      "\n",
      "model : Decision Tree\n",
      "\n",
      "\n",
      "model : Random Forest\n",
      "\n",
      "\n",
      "model : AdaBoost\n",
      "\n",
      "\n",
      "model : Logistic Regression\n",
      "model : Newral Network\n",
      "model : XGBoost\n",
      "====================result=====================\n",
      "トレーニングデータに対する正解率： 0.89\n",
      "テストデータに対する正解率： 0.79\n",
      "テストデータに対する正解率： 0.82\n",
      "[0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0\n",
      " 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n",
      "418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Aug  5 16:10:43 2018\n",
    "\n",
    "@author: miyamototatsurou\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.svm import SVC #svm\n",
    "from sklearn.naive_bayes import GaussianNB # Gaussian Naive Bayse\n",
    "from sklearn import tree #decision tree\n",
    "from sklearn.ensemble import RandomForestClassifier #random forest\n",
    "from sklearn.ensemble import AdaBoostClassifier #AdaBoost\n",
    "from sklearn.linear_model import LogisticRegression #ロジスティック回帰\n",
    "from sklearn.neural_network import MLPClassifier#Newral Network\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def kesson_table(df): \n",
    "        null_val = df.isnull().sum()\n",
    "        percent = 100 * df.isnull().sum()/len(df)\n",
    "        kesson_table = pd.concat([null_val, percent], axis=1)\n",
    "        kesson_table_ren_columns = kesson_table.rename(\n",
    "        columns = {0 : '欠損数', 1 : '%'})\n",
    "        return kesson_table_ren_columns\n",
    "\n",
    "\n",
    "def pre_process(train, test):\n",
    "    #dataの欠損値を補完\n",
    "    train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n",
    "    train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n",
    "    test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\n",
    "    test['Fare'] = test['Fare'].fillna(test['Fare'].median())\n",
    "\n",
    "    \n",
    "    #dataの文字列要素を数値で置き換える\n",
    "    train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\n",
    "    train[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n",
    "    train[\"Embarked\"][train[\"Embarked\"] == \"S\" ] = 0\n",
    "    train[\"Embarked\"][train[\"Embarked\"] == \"C\" ] = 1\n",
    "    train[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2\n",
    "    test[\"Sex\"][test[\"Sex\"] == \"male\"] = 0\n",
    "    test[\"Sex\"][test[\"Sex\"] == \"female\"] = 1\n",
    "    test[\"Embarked\"][test[\"Embarked\"] == \"S\"] = 0\n",
    "    test[\"Embarked\"][test[\"Embarked\"] == \"C\"] = 1\n",
    "    test[\"Embarked\"][test[\"Embarked\"] == \"Q\"] = 2\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "def SVM(x_train, y_train):\n",
    "    print('model : SVM\\n\\n')\n",
    "    #clf = GridSearchCV(SVC(), parameters)\n",
    "    #clf.fit(x_train, y_train)\n",
    "    \n",
    "    # train SVC with searched paramters\n",
    "    #model = clf.best_estimator_\n",
    "    \n",
    "    model = SVC(random_state=None, kernel='rbf')\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    \n",
    "    return model, 'SVC.model'\n",
    "    \n",
    "    \n",
    "def NB(x_train, y_train):\n",
    "    print('model : Naive bayse\\n\\n')\n",
    "    model = GaussianNB() # 正規分布を仮定したベイズ分類\n",
    "    model.fit(x_train, y_train) # 学習をする\n",
    "\n",
    "    return model, 'NB.model'  \n",
    "\n",
    "def DT(x_train, y_train):\n",
    "    print('model : Decision Tree\\n\\n')\n",
    "    model = tree.DecisionTreeClassifier(max_depth=3)\n",
    "    model = model.fit(x_train, y_train)\n",
    "\n",
    "    return model, 'DT.model'\n",
    "\n",
    "def RF(x_train, y_train):\n",
    "    print('model : Random Forest\\n\\n')\n",
    "    #model = RandomForestClassifier(min_samples_leaf=3, random_state=0)\n",
    "    model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=15,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=51, n_jobs=4,\n",
    "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model, 'RF.model'\n",
    "\n",
    "def AdaBoost(x_train, y_train):\n",
    "    print('model : AdaBoost\\n\\n')\n",
    "    model = AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model, 'AdaBoost.model'\n",
    "\n",
    "def LR(x_train, y_train):\n",
    "    print('model : Logistic Regression')\n",
    "    model = LogisticRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return model, 'LR.model'\n",
    "\n",
    "\n",
    "\n",
    "def NN(x_train, y_train):\n",
    "    print('model : Newral Network')\n",
    "    model = MLPClassifier(solver=\"adam\",random_state=None, learning_rate_init=0.1,\n",
    "                          max_iter=200)\n",
    "    #MLPClassifier(hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’,\n",
    "                  #alpha=0.0001, batch_size=’auto’, learning_rate=’constant’, \n",
    "                  #learning_rate_init=0.001,random_state=None, tol=0.0001, verbose=False, \n",
    "                  #warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "                  #early_stopping=False, validation_fraction=0.1, beta_1=0.9, \n",
    "                  #beta_2=0.999, epsilon=1e-08)[source]\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model, 'NN.model'\n",
    "\n",
    "def XGB(x_train, y_train):\n",
    "    print('model : XGBoost')\n",
    "    model = xgb.XGBClassifier()\n",
    "    #MLPClassifier(hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’,\n",
    "                  #alpha=0.0001, batch_size=’auto’, learning_rate=’constant’, \n",
    "                  #learning_rate_init=0.001,random_state=None, tol=0.0001, verbose=False, \n",
    "                  #warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "                  #early_stopping=False, validation_fraction=0.1, beta_1=0.9, \n",
    "                  #beta_2=0.999, epsilon=1e-08)[source]\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model, 'NN.model'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    train = pd.read_csv(\"all/train.csv\")\n",
    "    test = pd.read_csv(\"all/test.csv\")\n",
    "    \n",
    "    #前処理\n",
    "    train, test = pre_process(train, test)\n",
    "\n",
    "    # 「train」の目的変数と説明変数の値を取得\n",
    "    target = train[\"Survived\"].values\n",
    "    #features_one = train[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values\n",
    "    features_one = train[[\"Pclass\",\"Age\",\"Sex\",\"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "\n",
    "\n",
    "     # 乱数を制御するパラメータ random_state は None にすると毎回異なるデータを生成する\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features_one, target, test_size=0.3, random_state=None )\n",
    "    \n",
    "    # データの標準化処理\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(x_train)\n",
    "    x_train_std = sc.transform(x_train)\n",
    "    x_test_std = sc.transform(x_test)\n",
    "    \n",
    "    #x_train_std = x_train\n",
    "    #x_test_std = x_test\n",
    "    \n",
    "    print('===================training classifier==================')\n",
    "    model1, model_name1 = SVM(x_train_std, y_train) #svmで分類\n",
    "    model2, model_name = NB(x_train_std, y_train) #Gaussian Naive Bayseで分類\n",
    "    model3, model_name = DT(x_train_std, y_train) #Decision Tree\n",
    "    model4, model_name = RF(x_train_std, y_train) #Random Forest\n",
    "    model5, model_name = AdaBoost(x_train_std, y_train) #AdaBoost\n",
    "    model6, model_name = LR(x_train_std, y_train) #Logistic Regression\n",
    "    model7, model_name = NN(x_train_std, y_train) #Newral Network\n",
    "    model8, model_name2 = XGB(x_train_std, y_train)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    print('====================result=====================')\n",
    "    # トレーニングデータに対する精度\n",
    "    #pred_train = model.predict(x_train_std)\n",
    "    #print(pred_train)\n",
    "    #accuracy_train = accuracy_score(y_train, pred_train)\n",
    "    print('トレーニングデータに対する正解率： %.2f' % accuracy_train)\n",
    "    \n",
    "    # テストデータに対する精度\n",
    "    pred_test1 = model1.predict(x_test_std)\n",
    "    pred_test2 = model2.predict(x_test_std)\n",
    "    pred_test3 = model3.predict(x_test_std)\n",
    "    pred_test4 = model4.predict(x_test_std)\n",
    "    pred_test5 = model5.predict(x_test_std)\n",
    "    pred_test6 = model6.predict(x_test_std)\n",
    "    pred_test7 = model7.predict(x_test_std)\n",
    "    pred_test8 = model8.predict(x_test_std)\n",
    "\n",
    "    accuracy_test_or = accuracy_score(y_test, np.logical_or(pred_test1, pred_test2))\n",
    "    print('テストデータに対する正解率： %.2f' % accuracy_test_or)\n",
    "    accuracy_test_and = accuracy_score(y_test, np.logical_and(pred_test1, pred_test8))\n",
    "    print('テストデータに対する正解率： %.2f' % accuracy_test_and)    \n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    # 「test」の説明変数の値を取得\n",
    "    #test_features = test[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values\n",
    "    test_features = test[[\"Pclass\",\"Age\",\"Sex\",\"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "    \n",
    "    # データの標準化処理\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(test_features)\n",
    "    test_features_std  = sc.transform(test_features)\n",
    "    \n",
    "    \n",
    "    # 「test」の説明変数を使ってモデルで予測\n",
    "    pred = model.predict(test_features_std)\n",
    "\n",
    "    \n",
    "    #予測データの中身を確認\n",
    "    print(pred)\n",
    "    print(len(pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # PassengerIdを取得\n",
    "    PassengerId = np.array(test[\"PassengerId\"]).astype(int)\n",
    "    # my_prediction(予測データ）とPassengerIdをデータフレームへ落とし込む\n",
    "    my_solution = pd.DataFrame(pred, PassengerId, columns = [\"Survived\"])\n",
    "    # my_tree_one.csvとして書き出し\n",
    "    my_solution.to_csv(\"my_tree_one.csv\", index_label = [\"PassengerId\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
